{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac877a3-fe64-4e0e-88f9-ec2c6ada66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\coding\\ai_learnoor\\learner_env\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from text_generation import Client\n",
    "import json\n",
    "import re\n",
    "import tiktoken\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33eb748a-c51b-4b52-a9d9-e8139cc88c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '0QGPOO4GHY3230X2I51YWXTXP8E3UDG0AVNOCO9O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2005d4-a54d-4261-bc03-80e16c460ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prep_and_prompt():\n",
    "    \n",
    "    def __init__(self, folder_path , url, api_key, file_path, enable_logging):\n",
    "        self.folder_path  = folder_path \n",
    "        self.url = url\n",
    "        self.api_key = api_key\n",
    "        self.file_path = file_path\n",
    "        self.enable_logging = enable_logging\n",
    "        self.story = None\n",
    "        self.segments = {}\n",
    "        self.files_processed = 0\n",
    "        self.json_objects_created = 0\n",
    "\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.story = f.read()\n",
    "    \n",
    "    def clean_whitespace(self):\n",
    "        self.story = re.sub(r'\\n{2,}', '\\n', self.story)\n",
    "        self.story = re.sub(r' {2,}', '\\n', self.story)\n",
    "        self.story = self.story.strip()\n",
    "        \n",
    "    def encode_data(self):\n",
    "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.num_tokens = self.encoding.encode(self.story)\n",
    "        \n",
    "    def segment_text(self):\n",
    "        self.segments = {}\n",
    "        current_segment = []\n",
    "        seg_num = 1\n",
    "        \n",
    "        # will loop untill segment has 1000 tokens\n",
    "        for token in self.num_tokens:\n",
    "            current_segment.append(token)\n",
    "            \n",
    "            # if >= 1000 will add this batch to dict\n",
    "            if len(current_segment) >= 1000:\n",
    "                segment_text = self.encoding.decode(current_segment)\n",
    "                self.segments[f'Segment: {seg_num}'] = segment_text\n",
    "                current_segment = []\n",
    "                seg_num += 1\n",
    "                \n",
    "        # grabs remaining tokens        \n",
    "        if current_segment:\n",
    "            segment_text = self.encoding.decode(current_segment)\n",
    "            self.segments[f'Segment: {seg_num}'] = segment_text\n",
    "        return self.segments\n",
    "\n",
    "    def generate_prompt(self, input_text):\n",
    "        \n",
    "    \n",
    "        prompt= f\"\"\"\n",
    "        Based on the following story segment '{input_text}', directly create a brief sci-fi story prompt. \n",
    "        Start the prompt immediately without any introduction, explanation, or additional words. \n",
    "        End the prompt without any concluding remarks or questions. Provide only the prompt, exactly as requested, nothing more, nothing less.\n",
    "        \"\"\"\n",
    "\n",
    "        payload = { \"input\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"sampling_params\": {\n",
    "                \"max_tokens\": 1000,\n",
    "                \"n\": 1,\n",
    "                \"best_of\": None,\n",
    "                \"presence_penalty\": 0,\n",
    "                \"frequency_penalty\": 0.2,\n",
    "                \"temperature\": 0.6,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": -1,\n",
    "                \"use_beam_search\": False,\n",
    "                \"ignore_eos\": False,\n",
    "                \"logprobs\": None\n",
    "            }\n",
    "        } }\n",
    "        headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": self.api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.post(self.url, json=payload, headers=headers)\n",
    "    \n",
    "        response_data = response.json()\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            job_id = response_data.get('id')\n",
    "            return job_id\n",
    "        else:\n",
    "            print(\"Failed to generate prompt:\", response_data)\n",
    "            return None\n",
    "        \n",
    "    def poll_for_result(self, job_id, interval=5):\n",
    "        status_url = f\"https://api.runpod.ai/v2/llama2-13b-chat/status/{job_id}\"  \n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"authorization\": self.api_key\n",
    "        }\n",
    "    \n",
    "        while True:\n",
    "            response = requests.get(status_url, headers=headers)\n",
    "            result = response.json()\n",
    "    \n",
    "            if result['status'] == 'COMPLETED':\n",
    "                output = result.get('output')\n",
    "                return output  \n",
    "            elif result['status'] in ['FAILED', 'ERROR']:\n",
    "                print(\"Error or Failed Status:\", result)\n",
    "                return result\n",
    "    \n",
    "            time.sleep(interval)  # Wait before polling again\n",
    "\n",
    "    \n",
    "    def dump_jsonl(self, json_object):\n",
    "        with open(self.file_path, 'a', encoding='utf-8') as f:\n",
    "            json_s = json.dumps(json_object)\n",
    "            f.write(json_s + '\\n')\n",
    "        if self.enable_logging:\n",
    "            self.json_objects_created += 1\n",
    "                  \n",
    "    def extract_to_prompt(self):\n",
    "        ''' \n",
    "        takes segmented input (dictionary) loops through,\n",
    "        \"gen_prompt\" & \"poll_for_result\" functions\n",
    "        takes llm gen prompt from output\n",
    "        and places in new prompt with input text\n",
    "        ''' \n",
    "        i = 1\n",
    "        # loop through segmented outputs\n",
    "        for _, text in self.segments.items():\n",
    "            input_text = text\n",
    "            job_id = self.generate_prompt(input_text)\n",
    "            if job_id:\n",
    "                output = self.poll_for_result(job_id)\n",
    "                \n",
    "                text = output['text'][0] if output['text'] else None\n",
    "                extracted_text = \"\"\n",
    "                \n",
    "                # extract text between \\n\\n\n",
    "                if text:\n",
    "                    matches = re.findall(r\"\\n\\n(.*?)(?:\\n\\n|$)\", text, re.DOTALL)\n",
    "                    if matches:\n",
    "                        extracted_text = matches[0].strip()\n",
    "                        json_obj = {\n",
    "                          \"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": \"You are the greatest sci-fi story author in the universe.\"},\n",
    "                            {\"role\": \"user\", \"content\": extracted_text},\n",
    "                            {\"role\": \"assistant\", \"content\": input_text}\n",
    "                          ]\n",
    "                        }\n",
    "        \n",
    "                        self.dump_jsonl(json_obj) # call jsonl func           \n",
    "            i += 1\n",
    "    \n",
    "    def process_file(self, file_path):\n",
    "        self.load_data(file_path)\n",
    "        self.clean_whitespace()\n",
    "        self.encode_data()\n",
    "        self.segment_text()\n",
    "        self.extract_to_prompt()\n",
    "        if self.enable_logging:\n",
    "            self.files_processed += 1\n",
    "\n",
    "    def execute(self):\n",
    "        ''' \n",
    "        checks if the entry is a file - if so calls \n",
    "        process_file method on each file\n",
    "        '''\n",
    "        for filename in os.listdir(self.folder_path):\n",
    "            full_path = os.path.join(self.folder_path, filename)\n",
    "            if os.path.isfile(full_path):\n",
    "                self.process_file(full_path)\n",
    "        if self.enable_logging:\n",
    "            print(f\"Total files processed: {self.files_processed}\")\n",
    "            print(f\"Total JSON objects created: {self.json_objects_created}\")\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "process = prep_and_prompt(folder_path=\"D:\\coding\\llms\\sci_storys\", \n",
    "                          url=\"https://api.runpod.ai/v2/llama2-13b-chat/runsync\", \n",
    "                          api_key=\"0QGPOO4GHY3230X2I51YWXTXP8E3UDG0AVNOCO9O\",\n",
    "                         file_path=\"D:\\coding\\llms\\output.jsonl\",\n",
    "                         enable_logging=True)  \n",
    "process.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34af609b-a743-4505-b916-c51af396af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\coding\\llms\\output.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93921088-ff3c-4f75-addd-52e6ee678ac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3642\n"
     ]
    }
   ],
   "source": [
    "def clean_whitespace(text):\n",
    "        text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "        text = re.sub(r' {2,}', '\\n', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "\n",
    "def load_data(data):\n",
    "    with open(data, 'r', encoding='utf-8') as f:\n",
    "        story = f.read()\n",
    "    \n",
    "    clean_story = clean_whitespace(story)\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = encoding.encode(clean_story)\n",
    "    print(len(num_tokens))\n",
    "\n",
    "    segments = {}\n",
    "    current_segment = []\n",
    "    seg_num = 1\n",
    "    \n",
    "    # will loop untill dict has 1000 tokens\n",
    "    for token in num_tokens:\n",
    "        current_segment.append(token)\n",
    "        \n",
    "        # if >= 1000 will add this batch to dict\n",
    "        if len(current_segment) >= 1000:\n",
    "            segment_text = encoding.decode(current_segment)\n",
    "            segments[f'Segment: {seg_num}'] = segment_text\n",
    "            current_segment = []\n",
    "            seg_num += 1\n",
    "            \n",
    "    # grabs remaining tokens        \n",
    "    if current_segment:\n",
    "        segment_text = encoding.decode(current_segment)\n",
    "        segments[f'Segment: {seg_num}'] = segment_text\n",
    "     \n",
    "    return segments\n",
    "\n",
    "segmented_data = load_data(\"D:\\coding\\llms\\sci_storys\\story4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "771ac104-0328-4a0a-8799-7d935ca5697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_prompt(input_text, api_key):\n",
    "    url = \"https://api.runpod.ai/v2/llama2-13b-chat/runsync\"\n",
    "\n",
    "    prompt= f\"\"\"\n",
    "    Based on the following story segment '{input_text}', directly create a brief sci-fi story prompt. \n",
    "    Start the prompt immediately without any introduction, explanation, or additional words. \n",
    "    End the prompt without any concluding remarks or questions. Provide only the prompt, exactly as requested, nothing more, nothing less.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    payload = { \"input\": {\n",
    "        \"prompt\": prompt,\n",
    "        \"sampling_params\": {\n",
    "            \"max_tokens\": 1000,\n",
    "            \"n\": 1,\n",
    "            \"best_of\": None,\n",
    "            \"presence_penalty\": 0,\n",
    "            \"frequency_penalty\": 0.2,\n",
    "            \"temperature\": 0.6,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": -1,\n",
    "            \"use_beam_search\": False,\n",
    "            \"ignore_eos\": False,\n",
    "            \"logprobs\": None\n",
    "        }\n",
    "    } }\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"authorization\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    response_data = response.json()\n",
    "\n",
    "    job_id = response_data.get('id')\n",
    "    return job_id  \n",
    "    \n",
    "\n",
    "def poll_for_result(request_id, api_key, interval=5):\n",
    "    status_url = f\"https://api.runpod.ai/v2/llama2-13b-chat/status/{request_id}\"  \n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"authorization\": api_key\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(status_url, headers=headers)\n",
    "        result = response.json()\n",
    "\n",
    "        if result['status'] == 'COMPLETED':\n",
    "            output = result.get('output')\n",
    "            return output  \n",
    "        elif result['status'] in ['FAILED', 'ERROR']:\n",
    "            print(\"Error or Failed Status:\", result)\n",
    "            return result\n",
    "\n",
    "        time.sleep(interval)  # Wait before polling again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c7b4812-f3ea-4b16-acd7-726c423cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_to_prompt(segmented_data):\n",
    "    ''' \n",
    "    takes segmented input (dictionary) loops through,\n",
    "    \"gen_prompt\" & \"poll_for_result\" functions\n",
    "    takes llm gen prompt from output\n",
    "    and places in new prompt with input text\n",
    "    ''' \n",
    "    i = 1\n",
    "    json_objects = []\n",
    "    # loop through segmented outputs\n",
    "    for _, text in segmented_data.items():\n",
    "        input_text = text\n",
    "        job_id = gen_prompt(input_text, api_key)\n",
    "        if job_id:\n",
    "            output = poll_for_result(job_id, api_key)\n",
    "            \n",
    "            text = output['text'][0] if output['text'] else None\n",
    "            extracted_text = \"\"\n",
    "            \n",
    "            # extract text between \\n\\n\n",
    "            if text:\n",
    "                matches = re.findall(r\"\\n\\n(.*?)(?:\\n\\n|$)\", text, re.DOTALL)\n",
    "                if matches:\n",
    "                    extracted_text = matches[0].strip()\n",
    "                    json_obj = {\n",
    "                      \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are the greatest sci-fi story author in the universe.\"},\n",
    "                        {\"role\": \"user\", \"content\": extracted_text},\n",
    "                        {\"role\": \"assistant\", \"content\": input_text}\n",
    "                      ]\n",
    "                    }\n",
    "                    json_objects.append(json_obj) \n",
    "        i += 1\n",
    "\n",
    "        return json_objects\n",
    "json_output = extract_to_prompt(segmented_data)\n",
    "json_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "llm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
